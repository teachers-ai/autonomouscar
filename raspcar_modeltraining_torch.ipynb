{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/teachers-ai/autonomouscardata.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_SoTvGeOrmAb",
        "outputId": "f397db99-2a2f-4015-c2dc-f88ab60aa468"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'autonomouscardata'...\n",
            "remote: Enumerating objects: 405, done.\u001b[K\n",
            "remote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
            "remote: Total 405 (delta 0), reused 6 (delta 0), pack-reused 399 (from 1)\u001b[K\n",
            "Receiving objects: 100% (405/405), 485.63 MiB | 24.22 MiB/s, done.\n",
            "Updating files: 100% (399/399), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xa0_KTuPPaWU",
        "outputId": "81842352-6979-4727-c5c4-b03bb1964639"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "# prompt: write a code to read from google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "root_path = 'drive/MyDrive/raspcar/hanuman/'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "gHvBYGC9P7W5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JRelWBt-P7hP"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from torchvision.io import read_image\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import DataLoader\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "class CustomImageDataset(Dataset):\n",
        "    def __init__(self, root_path, transform=None):\n",
        "\n",
        "        self.root_path = root_path\n",
        "        self.transform = transform\n",
        "        self.image_files = os.listdir(root_path)\n",
        "        self.target = []\n",
        "        # Iterate over the files and plot them\n",
        "        for image_file in self.image_files:\n",
        "          # Read the image file\n",
        "          if  \"L\" in image_file :\n",
        "            y = 0\n",
        "          elif \"F\" in image_file:\n",
        "            y = 1\n",
        "          elif \"R\" in image_file:\n",
        "            y = 2\n",
        "          self.target.append(y)\n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.root_path, self.image_files[idx])\n",
        "        image = Image.open(img_path).resize((200, 50))\n",
        "        label = self.target[idx]\n",
        "        return self.transform(image), label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZYqwaOpoXPr6"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) # Normalize to [-1, 1]\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zr4xvgvCP7od"
      },
      "outputs": [],
      "source": [
        "dataset = CustomImageDataset(root_path, transform=transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8pmVbHfcP7wA"
      },
      "outputs": [],
      "source": [
        "train_dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
        "x,y =next(iter(train_dataloader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R9UGrFaebFBB"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WAg1S_rnPk3q"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, 3)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(16, 32, 3)\n",
        "        self.fc1 = nn.Linear(16896, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "net = Net()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "sDKQOs5_hfUk"
      },
      "outputs": [],
      "source": [
        "#net(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zxgPYrw0PzMl"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.001) # Use Adam optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i3Nw0d4OUkc5"
      },
      "outputs": [],
      "source": [
        "# prompt: write a function for model accuracy\n",
        "\n",
        "def model_accuracy(outputs, labels):\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "    correct = (predicted == labels).sum().item()\n",
        "    accuracy = correct / len(labels)\n",
        "    return accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "XVixjU5dP39E",
        "outputId": "31c95d66-c039-4a73-bcb7-de88e9ead153"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Accuracy: 0.7617984693877551\n",
            "Epoch 1, Accuracy: 0.883609693877551\n",
            "Epoch 2, Accuracy: 0.9317602040816327\n",
            "Epoch 3, Accuracy: 0.9451530612244898\n",
            "Finished Training\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(4):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(train_dataloader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 2000 == 32:    # print every 2000 mini-batches\n",
        "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
        "            running_loss = 0.0\n",
        "    # calc accuracy\n",
        "    with torch.no_grad():\n",
        "      accuracy =[]\n",
        "      for i, data in enumerate(train_dataloader, 0):\n",
        "        inputs, labels = data\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(inputs)\n",
        "        acc= model_accuracy(outputs, labels)\n",
        "        accuracy.append(acc)\n",
        "\n",
        "      print(f'Epoch {epoch}, Accuracy: {sum(accuracy)/len(accuracy)}')\n",
        "\n",
        "print('Finished Training')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ymotqQZVdhKa"
      },
      "outputs": [],
      "source": [
        "model_scripted = torch.jit.script(net) # Export to TorchScript\n",
        "model_scripted.save('pt_ram1.pt')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_new = torch.jit.load('pt_ram1.pt')\n",
        "model_new.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nYrKI5PvTUN_",
        "outputId": "3546d201-05d8-406f-9faf-7c346172cc0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RecursiveScriptModule(\n",
              "  original_name=Net\n",
              "  (conv1): RecursiveScriptModule(original_name=Conv2d)\n",
              "  (pool): RecursiveScriptModule(original_name=MaxPool2d)\n",
              "  (conv2): RecursiveScriptModule(original_name=Conv2d)\n",
              "  (fc1): RecursiveScriptModule(original_name=Linear)\n",
              "  (fc2): RecursiveScriptModule(original_name=Linear)\n",
              "  (fc3): RecursiveScriptModule(original_name=Linear)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_QPZM8Ml9Rh",
        "outputId": "0d26f440-d80e-43d9-a96d-35b23620a44d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Accuracy: 0.9955357142857143\n"
          ]
        }
      ],
      "source": [
        "accuracy =[]\n",
        "for i, data in enumerate(train_dataloader, 0):\n",
        "  inputs, labels = data\n",
        "  outputs = model_new(inputs)\n",
        "  acc= model_accuracy(outputs, labels)\n",
        "  accuracy.append(acc)\n",
        "\n",
        "print(f\" Accuracy: {sum(accuracy)/len(accuracy)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "prQeyIwamW5i",
        "outputId": "4a35a673-dca3-4eea-939c-76ad32a445c3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([14, 3, 50, 200])"
            ]
          },
          "execution_count": 208,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xtgA0WGfnQ5t"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OS0XBAfDm7mA"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) # Normalize to [-1, 1]\n",
        "])\n",
        "#model = torch.load('hanuman1.pth', weights_only=False)\n",
        "\n",
        "#model.eval()\n",
        "\n",
        "image = Image.open(\"/content/drive/MyDrive/raspcar/hanuman/19_img_R.jpg\").resize((200, 50))\n",
        "image =transform(image).unsqueeze(0)\n",
        "_, predicted = torch.max(model(image), 1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8P2owCdn9Q4",
        "outputId": "32c53c0d-9003-4541-852f-e0c41aa04595"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "predicted.item()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.jit.load('pt_model1.pt')\n",
        "model.eval()\n",
        "image = Image.open(\"/content/drive/MyDrive/raspcar/hanuman/19_img_R.jpg\").resize((200, 50))\n",
        "image =transform(image).unsqueeze(0)\n",
        "_, predicted = torch.max(model(image), 1)"
      ],
      "metadata": {
        "id": "3GfwhNrWRZew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FilNn9wUniiD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-bc7fx6fno4V"
      },
      "outputs": [],
      "source": [
        "#image = cv2.imread(\"/content/drive/MyDrive/raspcar/hanuman/19_img_R.jpg\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-nRlsS3KMNmC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pgwaKTwNMPWD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SG8vV0ddMmuH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "s5JBCpCjRHvW"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}